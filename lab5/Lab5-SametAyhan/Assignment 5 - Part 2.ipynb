{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Assignment 5 - Part 2"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"newsarticles/news10.html\", \"r\") as myfile:\n",
      "    data = myfile.read()   \n",
      "sentences = nltk.sent_tokenize(data)\n",
      "sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
      "sentences = [nltk.pos_tag(sent) for sent in sentences]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 153
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2.1 Named Entity Recognition"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chunked = nltk.ne_chunk(sentences[0])\n",
      "\n",
      "for n in chunked:\n",
      "    if isinstance(n, nltk.tree.Tree):               \n",
      "        if n.label() == 'PERSON':\n",
      "            entity = \"\"\n",
      "            for i in n.leaves():\n",
      "                 entity = entity + \" \" + i[0]\n",
      "            print entity, \", PERSON\"\n",
      "        elif n.label() == 'ORGANIZATION':\n",
      "            entity = \"\"\n",
      "            for i in n.leaves():\n",
      "                 entity = entity + \" \" + i[0]\n",
      "            print entity, \", ORGANIZATION\"\n",
      "        elif n.label() == 'LOCATION':\n",
      "            entity = \"\"\n",
      "            for i in n.leaves():\n",
      "                 entity = entity + \" \" + i[0]\n",
      "            print entity, \", LOCATION\"\n",
      "        elif n.label() == 'DATE':\n",
      "            entity = \"\"\n",
      "            for i in n.leaves():\n",
      "                 entity = entity + \" \" + i[0]\n",
      "            print entity, \", DATE\"\n",
      "        elif n.label() == 'TIME':\n",
      "            entity = \"\"\n",
      "            for i in n.leaves():\n",
      "                 entity = entity + \" \" + i[0]\n",
      "            print entity, \", TIME\"\n",
      "        elif n.label() == 'MONEY':\n",
      "            entity = \"\"\n",
      "            for i in n.leaves():\n",
      "                 entity = entity + \" \" + i[0]\n",
      "            print entity, \", MONEY\"\n",
      "        elif n.label() == 'PERCENT':\n",
      "            entity = \"\"\n",
      "            for i in n.leaves():\n",
      "                 entity = entity + \" \" + i[0]\n",
      "            print entity, \", PERCENT\"\n",
      "        elif n.label() == 'FACILITY':\n",
      "            entity = \"\"\n",
      "            for i in n.leaves():\n",
      "                 entity = entity + \" \" + i[0]\n",
      "            print entity, \", FACILITY\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Reuters , ORGANIZATION\n",
        " Gaza , LOCATION\n",
        " Sinai , ORGANIZATION\n"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2.2 Relation Extraction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "roles = \"\"\"\n",
      "\"\"\"\n",
      "ROLES = re.compile(roles, re.VERBOSE)\n",
      "\n",
      "for doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):\n",
      "    lcon = rcon = False\n",
      "    for rel in nltk.sem.extract_rels('ORG', 'LOC', doc, corpus='ieer', pattern = ROLES):\n",
      "        print(nltk.sem.rtuple(rel, lcon=lcon, rcon=rcon))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ORG: u'NPR'] u\"'s\" [LOC: u'Washington']\n",
        "[ORG: u'WHYY'] u'in' [LOC: u'Philadelphia']\n",
        "[ORG: u'McGlashan &AMP; Sarrail'] u'firm in' [LOC: u'San Mateo']\n",
        "[ORG: u'Freedom Forum'] u'in' [LOC: u'Arlington']\n",
        "[ORG: u'Imagine Media'] u'of' [LOC: u'Brisbane']\n",
        "[ORG: u'Audio Net'] u', a' [LOC: u'Dallas']\n",
        "[ORG: u'White House'] u\"support and facing only tepid opposition from the nation's governors,\" [LOC: u'Silicon Valley']\n",
        "[ORG: u'Brookings Institution'] u', the research group in' [LOC: u'Washington']\n",
        "[ORG: u'Idealab'] u', a self-described business incubator based in' [LOC: u'Los Angeles']\n",
        "[ORG: u'Open Text'] u', based in' [LOC: u'Waterloo']\n",
        "[ORG: u'WGBH'] u'in' [LOC: u'Boston']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ORG: u'Congress'] u'and a noted expert on' [LOC: u'Russia']\n",
        "[ORG: u'Home Box Office'] u'documentary about a' [LOC: u'New York']\n",
        "[ORG: u'Bastille Opera'] u'in' [LOC: u'Paris']\n",
        "[ORG: u'Met'] u'. After returning to' [LOC: u'New York']\n",
        "[ORG: u'Omnicom'] u'in' [LOC: u'New York']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ORG: u'DDB Needham'] u'in' [LOC: u'New York']\n",
        "[ORG: u'DDB Needham'] '' [LOC: u'U.S.']\n",
        "[ORG: u'Kaplan Thaler Group'] u'in' [LOC: u'New York']\n",
        "[ORG: u'BBDO South'] u'in' [LOC: u'Atlanta']\n",
        "[ORG: u'Georgia-Pacific'] u'in' [LOC: u'Atlanta']\n"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "vnv = \"\"\"\n",
      "\"\"\"\n",
      "AT = re.compile(vnv, re.VERBOSE)\n",
      "for doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):\n",
      "    for rel in nltk.sem.extract_rels('PER', 'ORG', doc, corpus='ieer', pattern = AT):\n",
      "        print(nltk.sem.clause(rel, relsym=\"AT\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AT(u'bob_edwards', u'national_public_radio')\n",
        "AT(u'wertheimer', u'npr')\n",
        "AT(u'mike_godwin', u'electronic_frontier_foundation')\n",
        "AT(u'cohn', u'mcglashan_&_sarrail')\n",
        "AT(u'lillian_r_berkman', u'center_for_internet_and_society')\n",
        "AT(u'james_boyle', u'american_university')\n",
        "AT(u'robert_mergess', u'berkeley_center_for_law_and_technology')\n",
        "AT(u'jack_balkin', u'yale')\n",
        "AT(u'pam_samuelson', u'berkeley')\n",
        "AT(u'clinton', u'berkeley')\n",
        "AT(u'samuelson', u'berkeley')\n",
        "AT(u'samuelson', u'harvard')\n",
        "AT(u'michael_froomkin', u'university_of_miami')\n",
        "AT(u'dan_burk', u'seton_hall_university')\n",
        "AT(u'david_post', u'cyberspace_law_institute')\n",
        "AT(u'frank_easterbrook', u'7th_us_circuit_court_of_appeals')\n",
        "AT(u'jones', u'qradio')\n",
        "AT(u'jones', u'qradio')\n",
        "AT(u'vern_fotheringham', u'qradio')\n",
        "AT(u'william_gale', u'brookings_institution')\n",
        "AT(u'joel_slemrod', u'university_of_michigan')\n",
        "AT(u'alan_braverman', u'credit_suisse_first_boston')\n",
        "AT(u'bill_gross', u'idealab')\n",
        "AT(u'abe_kleinfield', u'open_text')\n",
        "AT(u'braverman', u'yahoo')\n",
        "AT(u'kaufman', u'tv_books_llc')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "AT(u'kaufman', u'tv_books')\n",
        "AT(u'michael_coffey', u'publishers_weekly')\n",
        "AT(u'lorne_michaels', u'tv_books')\n",
        "AT(u'james_billington', u'congress')\n",
        "AT(u'sherry_lansing', u'paramount_motion_picture_group')\n",
        "AT(u'lindsay_doran', u'united_artists')\n",
        "AT(u'baz_luhrmann', u'mtv')\n",
        "AT(u'laura_ziskin', u'fox_2000')\n",
        "AT(u'rick_yorn', u'addis-wechsler_&_associates')\n",
        "AT(u'tom_rothman', u'20th_century_fox')\n",
        "AT(u'charlotte_forest', u'homestead_editorial')\n",
        "AT(u'richard_strauss', u'la_scala')\n",
        "AT(u'wilson', u'met')\n",
        "AT(u'philip_glass', u'met')\n",
        "AT(u'john_wren', u'omnicom')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "AT(u'steve_davis', u'wells')\n",
        "AT(u'wren', u'wells')\n",
        "AT(u'charlie_moss', u'moss/dragoti')\n",
        "AT(u'ken_kaess', u'ddb_needham')\n",
        "AT(u'lawrence', u'wells')\n",
        "AT(u'linda_kaplan_thaler', u'wells')\n",
        "AT(u'kaplan_thaler', u'wells')\n",
        "AT(u'kaplan_thaler', u\"toys_``r''_us\")\n",
        "AT(u'kaplan_thaler', u'wells')\n",
        "AT(u'ken_haldin', u'georgia-pacific')\n",
        "AT(u'davis', u'wells')\n",
        "AT(u'nan_a_talese', u'doubleday')\n"
       ]
      }
     ],
     "prompt_number": 101
    }
   ],
   "metadata": {}
  }
 ]
}